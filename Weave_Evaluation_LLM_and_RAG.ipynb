{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install weave"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7YXCDvxPI1-",
        "outputId": "9c4ab6c8-ac6b-4c5c-d707-a714d32537a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: weave in /usr/local/lib/python3.10/dist-packages (0.51.27)\n",
            "Requirement already satisfied: emoji>=2.12.1 in /usr/local/lib/python3.10/dist-packages (from weave) (2.14.0)\n",
            "Requirement already satisfied: gql[aiohttp,requests] in /usr/local/lib/python3.10/dist-packages (from weave) (3.5.0)\n",
            "Requirement already satisfied: jsonschema>=4.23.0 in /usr/local/lib/python3.10/dist-packages (from weave) (4.23.0)\n",
            "Requirement already satisfied: numpy>1.21.0 in /usr/local/lib/python3.10/dist-packages (from weave) (1.26.4)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from weave) (24.2)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from weave) (2.10.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from weave) (13.9.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /usr/local/lib/python3.10/dist-packages (from weave) (9.0.0)\n",
            "Requirement already satisfied: uuid-utils>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from weave) (0.10.0)\n",
            "Requirement already satisfied: wandb>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from weave) (0.19.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.23.0->weave) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.23.0->weave) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.23.0->weave) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.23.0->weave) (0.22.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave) (4.12.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (75.1.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.2 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave) (3.2.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave) (1.18.3)\n",
            "Requirement already satisfied: backoff<3.0,>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave) (2.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave) (3.7.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave) (3.11.11)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave) (1.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->weave) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->weave) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (0.2.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.0->gql[aiohttp,requests]->weave) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.0->gql[aiohttp,requests]->weave) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.0->gql[aiohttp,requests]->weave) (1.2.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.17.1->weave) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->weave) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2024.12.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YmjVC_y9MY-v"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import weave\n",
        "\n",
        "class ExtractFruitsModel(weave.Model):\n",
        "    model_name: str\n",
        "    prompt_template: str\n",
        "\n",
        "    @weave.op()\n",
        "    async def predict(self, sentence: str) -> dict:\n",
        "        client = openai.AsyncClient()\n",
        "\n",
        "        response = await client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": self.prompt_template.format(sentence=sentence)}\n",
        "            ],\n",
        "        )\n",
        "        result = response.choices[0].message.content\n",
        "        if result is None:\n",
        "            raise ValueError(\"No response from model\")\n",
        "        parsed = json.loads(result)\n",
        "        return parsed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import weave\n",
        "\n",
        "# Import Colab Secrets userdata module\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set OpenAI API key\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "weave.init('intro-example')\n",
        "\n",
        "model = ExtractFruitsModel(model_name='gpt-3.5-turbo-1106',\n",
        "                        prompt_template='Extract fields (\"fruit\": <str>, \"color\": <str>, \"flavor\": <str>) from the following text, as json: {sentence}')\n",
        "sentence = \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\"\n",
        "# print(asyncio.run(model.predict(sentence)))\n",
        "# if you're in a Jupyter Notebook, run:\n",
        "await model.predict(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHj6WBn-Mie5",
        "outputId": "2ebd9120-5177-42ab-9bf4-ae9c2c236c28"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openai/_response.py:684: RuntimeWarning: coroutine 'Evaluation.evaluate' was never awaited\n",
            "  def wrapped(*args: P.args, **kwargs: P.kwargs) -> AsyncResponseContextManager[AsyncAPIResponse[R]]:\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/simran_anand/intro-example/r/call/01944f89-d326-78b2-b35c-253d9c3e4055\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'taste like candy'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\",\n",
        "    \"Pounits are a bright green color and are more savory than sweet.\",\n",
        "    \"Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\n",
        "]\n",
        "labels = [\n",
        "    {'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'},\n",
        "    {'fruit': 'pounits', 'color': 'bright green', 'flavor': 'savory'},\n",
        "    {'fruit': 'glowls', 'color': 'pale orange', 'flavor': 'sour and bitter'}\n",
        "]\n",
        "examples = [\n",
        "    {'id': '0', 'sentence': sentences[0], 'target': labels[0]},\n",
        "    {'id': '1', 'sentence': sentences[1], 'target': labels[1]},\n",
        "    {'id': '2', 'sentence': sentences[2], 'target': labels[2]}\n",
        "]"
      ],
      "metadata": {
        "id": "3omsYedpMmiz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import weave\n",
        "from weave.scorers import MultiTaskBinaryClassificationF1\n",
        "\n",
        "weave.init('intro-example')\n",
        "\n",
        "@weave.op()\n",
        "def fruit_name_score(target: dict, output: dict) -> dict:\n",
        "    return {'correct': target['fruit'] == output['fruit']}\n",
        "\n",
        "evaluation = weave.Evaluation(\n",
        "    dataset=examples,\n",
        "    scorers=[\n",
        "        MultiTaskBinaryClassificationF1(class_names=[\"fruit\", \"color\", \"flavor\"]),\n",
        "        fruit_name_score\n",
        "    ],\n",
        ")\n",
        "# print(asyncio.run(evaluation.evaluate(model)))\n",
        "# if you're in a Jupyter Notebook, run:\n",
        "await evaluation.evaluate(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "tUunt7tcMpw0",
        "outputId": "1db2e731-c311-4686-9873-d09b072cf41a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m3\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'MultiTaskBinaryClassificationF1'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'fruit'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'f1'\u001b[0m: \u001b[1;36m0.8\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m0.6666666666666666\u001b[0m, \u001b[32m'recall'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'color'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'f1'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'recall'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'flavor'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'f1'\u001b[0m: \u001b[1;36m0.5\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m0.3333333333333333\u001b[0m, \u001b[32m'recall'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'fruit_name_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.6666666666666666\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m1.017319122950236\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'MultiTaskBinaryClassificationF1'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'fruit'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6666666666666666</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'color'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'flavor'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3333333333333333</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'fruit_name_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6666666666666666</span><span style=\"font-weight: bold\">}}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.017319122950236</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/simran_anand/intro-example/r/call/01944f8a-37bd-7972-a19d-5228d840dbd7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MultiTaskBinaryClassificationF1': {'fruit': {'f1': 0.8,\n",
              "   'precision': 0.6666666666666666,\n",
              "   'recall': 1.0},\n",
              "  'color': {'f1': 1.0, 'precision': 1.0, 'recall': 1.0},\n",
              "  'flavor': {'f1': 0.5, 'precision': 0.3333333333333333, 'recall': 1.0}},\n",
              " 'fruit_name_score': {'correct': {'true_count': 2,\n",
              "   'true_fraction': 0.6666666666666666}},\n",
              " 'model_latency': {'mean': 1.017319122950236}}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import weave\n",
        "\n",
        "# Initialize the W&B run and log outputs (as before)\n",
        "wandb.init(project='llm-output-comparison')\n",
        "\n",
        "# Simulate some outputs from two LLMs\n",
        "llm_1_outputs = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A journey of a thousand miles begins with a single step.\",\n",
        "    \"To be or not to be, that is the question.\"\n",
        "]\n",
        "\n",
        "llm_2_outputs = [\n",
        "    \"In the middle of difficulty lies opportunity.\",\n",
        "    \"Life is 10% what happens to us and 90% how we react to it.\",\n",
        "    \"The only impossible journey is the one you never begin.\"\n",
        "]\n",
        "\n",
        "# Log these outputs to W&B\n",
        "wandb.log({\n",
        "    \"llm_1_outputs\": llm_1_outputs,\n",
        "    \"llm_2_outputs\": llm_2_outputs\n",
        "})\n",
        "\n",
        "wandb.finish()\n",
        "\n",
        "# Fetch the logged data using wandb.Api()\n",
        "api = wandb.Api()\n",
        "\n",
        "# Fetch the specific run by its ID (replace this with your actual run ID)\n",
        "run = api.run(\"simran_anand/llm-output-comparison/7245ncd2\")  # replace 'run-id' with the actual run ID\n",
        "\n",
        "# Access the logged data from the run\n",
        "llm_1_outputs = run.summary.get(\"llm_1_outputs\", [])\n",
        "llm_2_outputs = run.summary.get(\"llm_2_outputs\", [])\n",
        "\n",
        "# Use Weave to visualize the outputs\n",
        "print(llm_1_outputs)\n",
        "\n",
        "print(llm_2_outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "hqW4NJrSihL7",
        "outputId": "fe0489c1-ea0d-4f28-f8b6-1fc7ee0588ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250110_094455-5wrd97vp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/simran_anand/llm-output-comparison/runs/5wrd97vp' target=\"_blank\">wobbly-frog-6</a></strong> to <a href='https://wandb.ai/simran_anand/llm-output-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/simran_anand/llm-output-comparison' target=\"_blank\">https://wandb.ai/simran_anand/llm-output-comparison</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/simran_anand/llm-output-comparison/runs/5wrd97vp' target=\"_blank\">https://wandb.ai/simran_anand/llm-output-comparison/runs/5wrd97vp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wobbly-frog-6</strong> at: <a href='https://wandb.ai/simran_anand/llm-output-comparison/runs/5wrd97vp' target=\"_blank\">https://wandb.ai/simran_anand/llm-output-comparison/runs/5wrd97vp</a><br> View project at: <a href='https://wandb.ai/simran_anand/llm-output-comparison' target=\"_blank\">https://wandb.ai/simran_anand/llm-output-comparison</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250110_094455-5wrd97vp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "['The quick brown fox jumps over the lazy dog.', 'A journey of a thousand miles begins with a single step.', 'To be or not to be, that is the question.']\n",
            "['In the middle of difficulty lies opportunity.', 'Life is 10% what happens to us and 90% how we react to it.', 'The only impossible journey is the one you never begin.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import weave\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# Weave will track the inputs, outputs and code of this function\n",
        "@weave.op()\n",
        "def extract_dinos(sentence: str) -> dict:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"In JSON format extract a list of `dinosaurs`, with their `name`,\n",
        "their `common_name`, and whether its `diet` is a herbivore or carnivore\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": sentence\n",
        "            }\n",
        "            ],\n",
        "            response_format={ \"type\": \"json_object\" }\n",
        "        )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# Initialise the weave project\n",
        "weave.init('jurassic-park')\n",
        "\n",
        "sentence = \"\"\"I watched as a Tyrannosaurus rex (T. rex) chased after a Triceratops (Trike), \\\n",
        "both carnivore and herbivore locked in an ancient dance. Meanwhile, a gentle giant \\\n",
        "Brachiosaurus (Brachi) calmly munched on treetops, blissfully unaware of the chaos below.\"\"\"\n",
        "\n",
        "result = extract_dinos(sentence)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8wdLhz9jY6v",
        "outputId": "97e4179f-3c84-4e70-ac90-f7dfc005851e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Weights & Biases user: simran_anand.\n",
            "View Weave data at https://wandb.ai/simran_anand/jurassic-park/weave\n",
            "🍩 https://wandb.ai/simran_anand/jurassic-park/r/call/01944f98-89f6-7402-ab5a-e079c6f81a79\n",
            "{\n",
            "  \"dinosaurs\": [\n",
            "    {\n",
            "      \"name\": \"Tyrannosaurus rex\",\n",
            "      \"common_name\": \"T. rex\",\n",
            "      \"diet\": \"carnivore\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Triceratops\",\n",
            "      \"common_name\": \"Trike\",\n",
            "      \"diet\": \"herbivore\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Brachiosaurus\",\n",
            "      \"common_name\": \"Brachi\",\n",
            "      \"diet\": \"herbivore\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import weave\n",
        "from weave import Model\n",
        "import numpy as np\n",
        "import json\n",
        "import asyncio\n",
        "\n",
        "# Examples we've gathered that we want to use for evaluations\n",
        "articles = [\n",
        "    \"Novo Nordisk and Eli Lilly rival soars 32 percent after promising weight loss drug results Shares of Denmarks Zealand Pharma shot 32 percent higher in morning trade, after results showed success in its liver disease treatment survodutide, which is also on trial as a drug to treat obesity. The trial “tells us that the 6mg dose is safe, which is the top dose used in the ongoing [Phase 3] obesity trial too,” one analyst said in a note. The results come amid feverish investor interest in drugs that can be used for weight loss.\",\n",
        "    \"Berkshire shares jump after big profit gain as Buffetts conglomerate nears $1 trillion valuation Berkshire Hathaway shares rose on Monday after Warren Buffetts conglomerate posted strong earnings for the fourth quarter over the weekend. Berkshires Class A and B shares jumped more than 1.5%, each. Class A shares are higher by more than 17% this year, while Class B has gained more than 18%. Berkshire was last valued at $930.1 billion, up from $905.5 billion where it closed on Friday, according to FactSet. Berkshire on Saturday posted fourth-quarter operating earnings of $8.481 billion, about 28 percent higher than the $6.625 billion from the year-ago period, driven by big gains in its insurance business. Operating earnings refers to profits from businesses across insurance, railroads and utilities. Meanwhile, Berkshires cash levels also swelled to record levels. The conglomerate held $167.6 billion in cash in the fourth quarter, surpassing the $157.2 billion record the conglomerate held in the prior quarter.\",\n",
        "    \"Highmark Health says its combining tech from Google and Epic to give doctors easier access to information Highmark Health announced it is integrating technology from Google Cloud and the health-care software company Epic Systems. The integration aims to make it easier for both payers and providers to access key information they need, even if it's stored across multiple points and formats, the company said. Highmark is the parent company of a health plan with 7 million members, a provider network of 14 hospitals and other entities\",\n",
        "    \"Rivian and Lucid shares plunge after weak EV earnings reports Shares of electric vehicle makers Rivian and Lucid fell Thursday after the companies reported stagnant production in their fourth-quarter earnings after the bell Wednesday. Rivian shares sank about 25 percent, and Lucids stock dropped around 17 percent. Rivian forecast it will make 57,000 vehicles in 2024, slightly less than the 57,232 vehicles it produced in 2023. Lucid said it expects to make 9,000 vehicles in 2024, more than the 8,428 vehicles it made in 2023.\",\n",
        "    \"Mauritius blocks Norwegian cruise ship over fears of a potential cholera outbreak Local authorities on Sunday denied permission for the Norwegian Dawn ship, which has 2,184 passengers and 1,026 crew on board, to access the Mauritius capital of Port Louis, citing “potential health risks.” The Mauritius Ports Authority said Sunday that samples were taken from at least 15 passengers on board the cruise ship. A spokesperson for the U.S.-headquartered Norwegian Cruise Line Holdings said Sunday that 'a small number of guests experienced mild symptoms of a stomach-related illness' during Norwegian Dawns South Africa voyage.\",\n",
        "    \"Intuitive Machines lands on the moon in historic first for a U.S. company Intuitive Machines Nova-C cargo lander, named Odysseus after the mythological Greek hero, is the first U.S. spacecraft to soft land on the lunar surface since 1972. Intuitive Machines is the first company to pull off a moon landing — government agencies have carried out all previously successful missions. The company's stock surged in extended trading Thursday, after falling 11 percent in regular trading.\",\n",
        "    \"Lunar landing photos: Intuitive Machines Odysseus sends back first images from the moon Intuitive Machines cargo moon lander Odysseus returned its first images from the surface. Company executives believe the lander caught its landing gear sideways on the surface of the moon while touching down and tipped over. Despite resting on its side, the company's historic IM-1 mission is still operating on the moon.\",\n",
        "]\n",
        "\n",
        "def docs_to_embeddings(docs: list) -> list:\n",
        "    openai = OpenAI()\n",
        "    document_embeddings = []\n",
        "    for doc in docs:\n",
        "        response = (\n",
        "            openai.embeddings.create(input=doc, model=\"text-embedding-3-small\")\n",
        "            .data[0]\n",
        "            .embedding\n",
        "        )\n",
        "        document_embeddings.append(response)\n",
        "    return document_embeddings\n",
        "\n",
        "article_embeddings = docs_to_embeddings(articles) # Note: you would typically do this once with your articles and put the embeddings & metadata in a database\n",
        "\n",
        "# We've added a decorator to our retrieval step\n",
        "@weave.op()\n",
        "def get_most_relevant_document(query):\n",
        "    openai = OpenAI()\n",
        "    query_embedding = (\n",
        "        openai.embeddings.create(input=query, model=\"text-embedding-3-small\")\n",
        "        .data[0]\n",
        "        .embedding\n",
        "    )\n",
        "    similarities = [\n",
        "        np.dot(query_embedding, doc_emb)\n",
        "        / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n",
        "        for doc_emb in article_embeddings\n",
        "    ]\n",
        "    # Get the index of the most similar document\n",
        "    most_relevant_doc_index = np.argmax(similarities)\n",
        "    return articles[most_relevant_doc_index]\n",
        "\n",
        "# We create a Model subclass with some details about our app, along with a predict function that produces a response\n",
        "class RAGModel(Model):\n",
        "    system_message: str\n",
        "    model_name: str = \"gpt-3.5-turbo-1106\"\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(self, question: str) -> dict: # note: `question` will be used later to select data from our evaluation rows\n",
        "        from openai import OpenAI\n",
        "        context = get_most_relevant_document(question)\n",
        "        client = OpenAI()\n",
        "        query = f\"\"\"Use the following information to answer the subsequent question. If the answer cannot be found, write \"I don't know.\"\n",
        "        Context:\n",
        "        \\\"\\\"\\\"\n",
        "        {context}\n",
        "        \\\"\\\"\\\"\n",
        "        Question: {question}\"\"\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": self.system_message},\n",
        "                {\"role\": \"user\", \"content\": query},\n",
        "            ],\n",
        "            temperature=0.0,\n",
        "            response_format={\"type\": \"text\"},\n",
        "        )\n",
        "        answer = response.choices[0].message.content\n",
        "        return {'answer': answer, 'context': context}\n",
        "\n",
        "weave.init('rag-qa')\n",
        "model = RAGModel(\n",
        "    system_message=\"You are an expert in finance and answer questions related to finance, financial services, and financial markets. When responding based on provided information, be sure to cite the source.\"\n",
        ")\n",
        "\n",
        "# Here is our scoring function uses our question and output to product a score\n",
        "@weave.op()\n",
        "async def context_precision_score(question, output):\n",
        "    context_precision_prompt = \"\"\"Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.\n",
        "    Output in only valid JSON format.\n",
        "\n",
        "    question: {question}\n",
        "    context: {context}\n",
        "    answer: {answer}\n",
        "    verdict: \"\"\"\n",
        "    client = OpenAI()\n",
        "\n",
        "    prompt = context_precision_prompt.format(\n",
        "        question=question,\n",
        "        context=output['context'],\n",
        "        answer=output['answer'],\n",
        "    )\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo-preview\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        response_format={ \"type\": \"json_object\" }\n",
        "    )\n",
        "    response_message = response.choices[0].message\n",
        "    response = json.loads(response_message.content)\n",
        "    return {\n",
        "        \"verdict\": int(response[\"verdict\"]) == 1,\n",
        "    }\n",
        "\n",
        "questions = [\n",
        "    {\"question\": \"What significant result was reported about Zealand Pharma's obesity trial?\"},\n",
        "    {\"question\": \"How much did Berkshire Hathaway's cash levels increase in the fourth quarter?\"},\n",
        "    {\"question\": \"What is the goal of Highmark Health's integration of Google Cloud and Epic Systems technology?\"},\n",
        "    {\"question\": \"What were Rivian and Lucid's vehicle production forecasts for 2024?\"},\n",
        "    {\"question\": \"Why was the Norwegian Dawn cruise ship denied access to Mauritius?\"},\n",
        "    {\"question\": \"Which company achieved the first U.S. moon landing since 1972?\"},\n",
        "    {\"question\": \"What issue did Intuitive Machines' lunar lander encounter upon landing on the moon?\"}\n",
        "]\n",
        "\n",
        "# We define an Evaluation object and pass our example questions along with scoring functions\n",
        "evaluation = weave.Evaluation(dataset=questions, scorers=[context_precision_score])\n",
        "await evaluation.evaluate(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "0-r_qPCQn173",
        "outputId": "3611eeac-c620-4648-b129-39e44e0ad223"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/tokenize.py:527: RuntimeWarning: coroutine 'ExtractFruitsModel.predict' was never awaited\n",
            "  pseudomatch = _compile(PseudoToken).match(line, pos)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/lib/python3.10/tokenize.py:527: RuntimeWarning: coroutine 'Evaluation.evaluate' was never awaited\n",
            "  pseudomatch = _compile(PseudoToken).match(line, pos)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/simran_anand/rag-qa/r/call/01944fa1-b661-7913-952d-cbdd739e62df\n",
            "🍩 https://wandb.ai/simran_anand/rag-qa/r/call/01944fa1-b874-76b0-b43d-15daea698bdb\n",
            "🍩 https://wandb.ai/simran_anand/rag-qa/r/call/01944fa1-ba1e-7cb2-b16f-58b5a2582160\n",
            "🍩 https://wandb.ai/simran_anand/rag-qa/r/call/01944fa1-bb35-7e52-9c44-caec14b2b877\n",
            "🍩 https://wandb.ai/simran_anand/rag-qa/r/call/01944fa1-bc38-72d3-81b0-c65087e89b65\n",
            "🍩 https://wandb.ai/simran_anand/rag-qa/r/call/01944fa1-bd8b-7560-9bbd-d3a3c23c67d2\n",
            "🍩 https://wandb.ai/simran_anand/rag-qa/r/call/01944fa1-be97-7051-94b0-d73a1f08c91f\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m7\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m7\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m7\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m7\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m7\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m7\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m7\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'context_precision_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'verdict'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m7\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m26.492431231907435\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'context_precision_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'verdict'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.492431231907435</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/simran_anand/rag-qa/r/call/01944fa1-c00e-73f0-aa79-696c8de443c9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_precision_score': {'verdict': {'true_count': 7,\n",
              "   'true_fraction': 1.0}},\n",
              " 'model_latency': {'mean': 26.492431231907435}}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0N8f-OHJoLeN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}